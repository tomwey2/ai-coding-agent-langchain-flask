services:
  # ----------------------------------------
  # CONTAINER 1: Der AI Coding Agent
  # ----------------------------------------
  ai-coding-agent:
    build: .
    container_name: ai-coding-agent
    ports:
      - "5000:5000"
    environment:
      # GitHub token is mandatory for repository access
      - GITHUB_TOKEN=${GHCR_AI_CODING_AGENT_TOKEN}
      
      # LLM API keys (only set if you want to use them)
      - MISTRAL_API_KEY=${MISTRAL_API_KEY:-}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      
      # Ollama API key (only if a key is needed)
      - OLLAMA_API_KEY=${OLLAMA_API_KEY:-}
      # Ollama base URL (only if you want to use Ollama not in a docker container)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-}
      
      # in which workspace the agent works
      - WORKSPACE=/coding-agent-workspace
      # which workbench the agent uses
      - WORKBENCH=workbench-backend
    env_file: .env
    volumes:
      - ./app/instance:/coding-agent/app/instance
      # mapping ./workspace to /workspace in container
      - ./workspace:/coding-agent-workspace
      # the socket to connect to the docker daemon
      - /var/run/docker.sock:/var/run/docker.sock

  # ----------------------------------------
  # CONTAINER 2: The Workbench
  # ----------------------------------------
  workbench-backend:
    image: maven:3.9-eclipse-temurin-21
    container_name: workbench-backend
    # this command keeps the container alive
    command: tail -f /dev/null
    # in which workspace=working_dir the commands are executed
    working_dir: /coding-agent-workspace
    volumes:
      # HIER: Exakt gleicher Pfad wie beim Agenten, damit Pfad-Befehle stimmen
      - ./workspace:/coding-agent-workspace
      # Optional: Maven Cache (macht Tests schneller)
      - ~/.m2:/root/.m2
      # the socket to connect to the docker daemon
      - /var/run/docker.sock:/var/run/docker.sock
